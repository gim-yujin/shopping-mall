# Shopping Mall 프로젝트 상세 설명서

> 이 문서는 **대규모 트래픽**과 **동시성 문제**를 핵심 과제로 삼아 구현된 Shopping Mall 프로젝트의 문제 해결 과정을 정리한 기술 문서입니다.  
> 단순 기능 나열이 아니라, **어떤 문제를 어떤 방식으로 풀었는지**, **왜 그 기술을 선택했는지**, **대안 대비 트레이드오프는 무엇인지**를 중심으로 작성했습니다.

---

## 1. 프로젝트 성격과 핵심 가치

### 1.1 프로젝트 한 줄 요약
- Spring Boot + PostgreSQL 기반의 이커머스 서비스이며, 주문/재고/쿠폰/리뷰/검색 도메인에서 발생하는 **고부하/동시성 이슈를 실무형으로 해결**하는 데 초점을 둔 프로젝트입니다.

### 1.2 가장 중요한 역량: 문제 해결 능력
이 프로젝트에서의 “문제 해결 능력”은 다음 4단계로 정의됩니다.

1. **증상 관찰**: 느린 응답, 오버셀링, 데드락, 중복 발급, N+1 등
2. **원인 식별**: 락 경합, 잘못된 인덱스/쿼리, 커넥션 풀 병목, 트랜잭션 경계 불명확
3. **해결 전략 적용**: 인덱싱, 쿼리 튜닝, 캐싱, 비동기화, OSIV off, 풀 사이즈 최적화
4. **검증 자동화**: 동시성 테스트(overselling/deadlock/coupon/cart), 정합성 검증

---

## 2. 성능·동시성 설계 원칙

### 2.1 데이터 접근 원칙
- 읽기/쓰기 경로 분리
- 트랜잭션 길이 최소화
- 핫 경로(상품 목록/상세/검색)는 캐시 우선
- 대용량 테이블(order_items 등)은 인덱스 우선 설계

### 2.2 동시성 원칙
- “정합성 우선” 경로(주문, 쿠폰)는 **비관적 락**으로 직렬화
- “토글/카운트” 경로(리뷰 helpful)는 DB의 **UNIQUE + ON CONFLICT** 활용
- “사용자별 단위 자원” 경로(장바구니)는 **Advisory Lock**으로 직렬화
- 데드락 회피를 위해 **자원 획득 순서 통일(product_id 오름차순)**

### 2.3 운영 관점 원칙
- OSIV off로 커넥션 점유 시간 단축
- HikariCP를 서버 코어 기준으로 고정 풀 운영
- SQL/바인딩 로그 레벨 최소화로 I/O 오버헤드 감소

---

## 3. 문제별 해결 전략 (핵심)

## 3.1 인덱싱 전략

### 문제
- `products`, `orders`, `order_items`, `reviews`, `search_logs`는 조회 빈도와 데이터량이 커서 풀스캔 비용이 큼.

### 적용 방법
- 검색/정렬/필터 패턴에 맞춘 복합 인덱스 구성
- Full-Text Search용 GIN 인덱스
- 할인 상품 전용 partial expression index
- 통계성 조회를 위한 covering index(`INCLUDE`)

### 대표 사례
1. **상품 검색 FTS**
   - `to_tsvector('simple', product_name)` GIN 인덱스
2. **딜 상품 정렬 최적화**
   - `(original_price - price) DESC` + `WHERE is_active=true AND original_price > price` partial index
3. **주문 상세 대용량 대응**
   - `order_items(product_id, created_at) INCLUDE (quantity, subtotal)` covering index

### 결과
- 대용량 구간에서 정렬/필터 쿼리를 인덱스 스캔 중심으로 유도할 수 있게 설계됨.
- 스키마 레벨에서 “총 15개 테이블, 50+ 인덱스”를 명시해 확장성 전제로 운영 가능.

### 왜 이 방법인가? (대안 비교)
- 대안: 애플리케이션 메모리 정렬/필터  
  → 데이터량이 커질수록 네트워크/메모리 비용 폭증
- 선택: DB 인덱스 기반 정렬/필터  
  → DB가 가장 잘하는 작업(정렬/검색)을 DB에 맡겨 전체 비용 최소화

---

## 3.2 쿼리 튜닝 & N+1 억제

### 문제
- 장바구니→주문, 사용자 쿠폰 목록, 상품 상세 등에서 연관 엔티티 접근 시 N+1 발생 가능.

### 적용 방법
- `JOIN FETCH`를 사용해 필요한 연관을 한 번에 로딩
- 페이지 쿼리는 `countQuery` 분리로 카운트 비용 통제
- fallback 검색(FTS 결과 없음 시 LIKE)으로 정확도/복원력 균형

### 대표 사례
- `CartRepository.findByUserIdWithProduct`: 장바구니 + 상품 동시 조회
- `UserCouponRepository.findByUserId`: 쿠폰 페이지 조회 시 쿠폰 엔티티 fetch join
- `ProductRepository.findByIdWithCategory`: 상세 페이지에서 카테고리 즉시 로딩

### 결과
- 주문 생성 시점의 DB 왕복 횟수와 LAZY 초기화 부하를 줄여 트랜잭션 수행 시간이 단축됨.

### 왜 이 방법인가? (대안 비교)
- 대안: EntityGraph 남발 또는 전역 EAGER  
  → 단순해 보이지만 불필요한 조인/메모리 사용 증가 위험
- 선택: “경로별 최소 JOIN FETCH”  
  → 필요한 곳만 명시적으로 최적화 가능

---

## 3.3 캐싱 (Caffeine)

### 문제
- 홈/목록/상세/검색/리뷰 목록은 읽기 트래픽 집중 구간으로 동일 질의 반복이 많음.

### 적용 방법
- `@Cacheable`로 핫 경로 캐싱: `bestSellers`, `newArrivals`, `deals`, `productList`, `productDetail`, `searchResults`, `productReviews` 등
- 캐시 만료/용량: `expireAfterWrite=5m`, `maximumSize=100`
- `recordStats()` + 주기적 로깅으로 hit/miss 관측

### 결과
- 동일 요청 반복 시 DB 접근을 우회하여 읽기 부하 완화.
- 캐시 통계 수집으로 운영 중 튜닝 근거 확보.

### 왜 이 방법인가? (대안 비교)
- 대안: Redis 분산 캐시  
  → 멀티 노드 확장에는 유리하지만, 단일 서비스 학습/개발 단계에서는 운영 복잡도 증가
- 선택: Caffeine 로컬 캐시  
  → 도입/관측/튜닝이 빠르고, 현재 구조에서 비용 대비 효과가 큼

---

## 3.4 OSIV off

### 문제
- OSIV on이면 뷰 렌더링 단계까지 영속성 컨텍스트/커넥션 점유가 길어질 수 있음.

### 적용 방법
- `spring.jpa.open-in-view: false`
- 서비스 계층에서 필요한 Lazy 컬렉션을 트랜잭션 내부에서 명시 초기화

### 결과
- 커넥션 점유 구간이 “실제 쿼리 수행 구간”으로 축소되어 고부하 시 풀 고갈 위험을 줄임.

### 왜 이 방법인가? (대안 비교)
- 대안: OSIV on 유지 + 템플릿에서 Lazy 접근 허용  
  → 개발은 편하지만, 트래픽이 커질수록 커넥션 홀드 타임이 증가
- 선택: OSIV off + 서비스에서 조회 책임 명시  
  → 운영 안정성과 성능 예측 가능성이 높음

---

## 3.5 HikariCP 풀 사이즈 최적화

### 문제
- 동시 요청 증가 시 DB 커넥션 풀이 병목이 되거나, 반대로 과도한 풀 크기로 DB 문맥 전환 비용이 증가할 수 있음.

### 적용 방법
- `maximum-pool-size: 17`, `minimum-idle: 17` (고정 풀)
- 기준: `(코어 수 × 2) + 1` 권장치
- `connection-timeout: 5000`으로 빠른 실패 설정

### 결과
- 풀 크기를 근거 기반으로 고정해 예측 가능한 처리량 확보.
- 타임아웃 단축으로 장애 상황에서 스레드 장기 대기 완화.

### 왜 이 방법인가? (대안 비교)
- 대안: 무작정 큰 풀  
  → DB CPU 경합/문맥전환 증가로 오히려 지연 악화 가능
- 선택: 코어 기반 합리적 고정 풀  
  → 안정적이고 재현 가능한 운영 특성

---

## 3.6 주문 동시성: 오버셀링 방지

### 문제
- 재고가 5개일 때 10명이 동시에 주문하면 재고 음수/오버셀링 발생 위험.

### 적용 방법
- `ProductRepository.findByIdWithLock`에 `PESSIMISTIC_WRITE` 적용
- 주문 트랜잭션 내부에서 재고 확인→차감 원자 처리
- 재고 변동을 `product_inventory_history`에 기록

### 검증 결과(테스트)
- 시나리오: 재고 5, 동시 주문 10
- 기대/검증: **정확히 5건 성공**, 재고 0, 음수 재고 없음

### 왜 이 방법인가? (대안 비교)
- 대안: 낙관적 락(version) + 재시도  
  → 충돌률 높은 핫 재고 상품에서는 재시도 폭증 가능
- 선택: 비관적 락  
  → 정합성 최우선 구간에서 결과 예측이 명확함

---

## 3.7 데드락 회피

### 문제
- 서로 다른 트랜잭션이 상품 락을 역순으로 잡으면 데드락 가능.

### 적용 방법
- 주문/취소 모두 상품을 `product_id` 오름차순으로 정렬 후 락 획득
- 동일 자원 획득 순서 강제

### 검증 결과(테스트)
- `@RepeatedTest(10)`으로 반복 검증
- 각 라운드에서 데드락 발생 수 `0`, 성공 수 `2`를 기대/검증

### 왜 이 방법인가? (대안 비교)
- 대안: DB deadlock retry만 의존  
  → 일시 복구는 가능하지만 실패율/지연 증가
- 선택: 사전 예방(락 순서 통일)  
  → 장애를 “복구”가 아닌 “회피”로 전환

---

## 3.8 쿠폰 발급 동시성: 초과/중복 방지

### 문제
- 한정 수량 쿠폰에서 동시 요청 시 초과 발급/중복 발급 위험.

### 적용 방법
- 쿠폰 조회 시 `PESSIMISTIC_WRITE`
- 사용자-쿠폰 `UNIQUE(user_id, coupon_id)` 제약
- 경쟁 조건에서 `DataIntegrityViolationException`을 비즈니스 예외로 매핑

### 검증 결과(테스트)
1. 총 5장 쿠폰 + 20명 동시 발급 → 실제 발급 5장, `used_quantity=5`
2. 같은 사용자 5회 동시 발급 → 실제 발급 1장, `used_quantity=1`

### 왜 이 방법인가? (대안 비교)
- 대안: 애플리케이션 단 `exists` 체크만 수행  
  → TOCTOU(검사-사용 사이 경쟁) 취약
- 선택: 락 + DB 유니크 제약 이중 방어  
  → 애플리케이션/DB 모두에서 정합성 보장

---

## 3.9 장바구니 동시성: Lost Update 방지

### 문제
- 같은 사용자가 동시에 장바구니를 수정하면 수량/항목 수가 꼬일 수 있음.

### 적용 방법
- 사용자 단위 `pg_advisory_xact_lock(userId)`으로 직렬화
- 중복 상품은 업데이트, 신규 상품은 제약조건 기반 삽입

### 검증 결과(테스트)
- 이미 담긴 상품에 동시 수량 증가 시 최종 수량이 기대치와 일치
- 49개 상태에서 5개 동시 추가 시 최대 50개 제한 유지

### 왜 이 방법인가? (대안 비교)
- 대안: JVM synchronized/분산락 미적용  
  → 다중 인스턴스 환경에서 무효
- 선택: DB 트랜잭션 스코프 advisory lock  
  → DB 일관성 경계 안에서 안전하게 직렬화

---

## 3.10 비동기화: 조회수/검색 로그

### 문제
- 조회수 증가, 검색 로그 저장을 동기 처리하면 읽기 API의 응답 지연과 커넥션 점유가 증가.

### 적용 방법
- `@Async("asyncExecutor")`로 쓰기 작업 분리
- 요청 경로는 읽기 중심으로 즉시 반환

### 결과
- hot row 쓰기 경합을 메인 요청 경로에서 분리하여 체감 응답성 개선.

### 왜 이 방법인가? (대안 비교)
- 대안: 메시지 큐(Kafka/RabbitMQ)  
  → 대규모 분산 처리엔 적합하지만 현재 범위 대비 운영 복잡도 큼
- 선택: Spring Async  
  → 코드 변경 최소화로 빠르게 병목 완화

---

## 4. 기술 선택 요약표

| 이슈 | 선택 기술 | 선택 이유 | 고려한 대안 | 대안을 택하지 않은 이유 |
|---|---|---|---|---|
| 재고 정합성 | PESSIMISTIC_WRITE | 오버셀링 방지 최우선 | Optimistic Lock | 충돌·재시도 비용 증가 |
| 데드락 | 락 획득 순서 통일 | 예방적 접근, 실패율 감소 | deadlock retry | 지연/실패를 사후 처리 |
| 반복 조회 부하 | Caffeine 캐시 | 단순·빠른 도입/관측 | Redis | 운영 복잡도 증가 |
| 커넥션 홀드 | OSIV off | 커넥션 점유 시간 단축 | OSIV on | 렌더링 단계까지 점유 가능 |
| DB 커넥션 병목 | Hikari 17 고정풀 | 예측 가능한 처리량 | 과대 풀 | DB 경합/문맥전환 증가 |
| 대용량 조회 | 복합/부분/커버링 인덱스 | 실행계획 최적화 | 앱단 필터링 | 데이터 커질수록 비효율 |
| 장바구니 동시수정 | Advisory Lock | user 단위 직렬화 명확 | 애플리케이션 락 | 멀티 인스턴스에서 취약 |

---

## 5. 운영/확장 시 다음 단계 제안

1. **관측 고도화**
   - p95/p99 API 지연, DB wait event, cache hit ratio 대시보드화
2. **캐시 계층 확장**
   - 멀티 인스턴스 전환 시 Redis 2nd-level cache 도입 검토
3. **읽기/쓰기 분리**
   - 레플리카(read replica) + 라우팅으로 read-heavy 구간 분산
4. **부하테스트 정례화**
   - 시나리오별 SLA(주문/검색/목록) 수치 기준선 관리
5. **쿼리 플랜 자동 점검**
   - 주요 SQL의 `EXPLAIN ANALYZE`를 CI 리그레션 체크로 포함

---

## 6. 결론

이 프로젝트의 본질은 “어떤 기술을 썼는가”보다, **문제를 구조적으로 분해하고 검증 가능한 방식으로 해결했는가**에 있습니다.

- 정합성이 중요한 곳은 락/제약조건으로 보수적으로,
- 읽기 트래픽이 중요한 곳은 캐시/비동기/인덱스로 공격적으로,
- 운영 안정성이 중요한 곳은 OSIV off/Hikari/로그 레벨 관리로 현실적으로.

즉, 이 프로젝트는 대규모 트래픽 환경에서의 엔지니어링 의사결정(성능 vs 정합성 vs 복잡도)의 균형을 실제 코드와 테스트로 증명하는 사례입니다.
